{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "51cd5ab9",
      "metadata": {
        "id": "51cd5ab9"
      },
      "source": [
        "# CNN implementation on Dementia Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c1af04a8",
      "metadata": {
        "id": "c1af04a8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2 as cv\n",
        "import os, sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a821ed6a",
      "metadata": {
        "id": "a821ed6a"
      },
      "outputs": [],
      "source": [
        "path1=''\n",
        "path2=''\n",
        "files1=os.listdir(path1)\n",
        "files2=os.listdir(path2)\n",
        "Num_files_N=len(files1)\n",
        "Num_files_D=len(files2)\n",
        "dataset_len=Num_files_N+Num_files_D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "x5_ppo3EW-_r"
      },
      "id": "x5_ppo3EW-_r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Num_files_N"
      ],
      "metadata": {
        "id": "FQxoPUfLXalK"
      },
      "id": "FQxoPUfLXalK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name=path1+'/'+files1[0]\n",
        "img=cv.imread(name)"
      ],
      "metadata": {
        "id": "ZthG-JvrXlbB"
      },
      "id": "ZthG-JvrXlbB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img,cmap='gray')"
      ],
      "metadata": {
        "id": "k-pnkR5lXvcB"
      },
      "id": "k-pnkR5lXvcB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "92UYHJpdX1_4"
      },
      "id": "92UYHJpdX1_4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "29252846",
      "metadata": {
        "id": "29252846"
      },
      "source": [
        "# Dataset Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7cdb862",
      "metadata": {
        "id": "f7cdb862"
      },
      "source": [
        "For every file\n",
        "\n",
        "1. Read the image\n",
        "2. Convert it to grayscale (Optional)\n",
        "3. Resize to (100,100)\n",
        "4. Preprocessing: Normalization\n",
        "5. Reshape to (100,100,1)\n",
        "6. Create the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ead1101",
      "metadata": {
        "id": "2ead1101"
      },
      "outputs": [],
      "source": [
        "data=np.zeros((dataset_len,100,100,3))\n",
        "label=[]\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "24314cc2",
      "metadata": {
        "id": "24314cc2"
      },
      "outputs": [],
      "source": [
        "for i in range(Num_files_N):\n",
        "    name=path1+'/'+files1[i]\n",
        "    img=cv.imread(name)\n",
        "    #img_gs=cv.cvtColor(img,cv.COLOR_RGB2GRAY)\n",
        "    img=cv.resize(img,(100,100))\n",
        "    img=img/255\n",
        "    #img_gs=img_gs.reshape(100,100,3)\n",
        "    data[i,:,:]=img\n",
        "    label.append('Normal')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[99].ndim"
      ],
      "metadata": {
        "id": "wgxfCc1ItCw4"
      },
      "id": "wgxfCc1ItCw4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5ac2af",
      "metadata": {
        "id": "6b5ac2af"
      },
      "outputs": [],
      "source": [
        "plt.imshow(data[99])\n",
        "#plt.imshow(cv.resize(data[0],(100,100)),cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b9df95c2",
      "metadata": {
        "id": "b9df95c2"
      },
      "outputs": [],
      "source": [
        "for i in range(Num_files_D):\n",
        "    name=path2+'/'+files2[i]\n",
        "    img=cv.imread(name)\n",
        "    img=cv.resize(img,(100,100))\n",
        "    img=img/255\n",
        "    data[i+Num_files_N,:,:]=img\n",
        "    label.append('Dementia')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c95186",
      "metadata": {
        "id": "04c95186"
      },
      "outputs": [],
      "source": [
        "#plt.imshow(data[100],cmap='gray')\n",
        "plt.imshow(cv.resize(data[100],(100,100)),cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label[100]"
      ],
      "metadata": {
        "id": "081Zu6qqtikC"
      },
      "id": "081Zu6qqtikC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a0ee2e56",
      "metadata": {
        "id": "a0ee2e56"
      },
      "source": [
        "Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ab8c94e7",
      "metadata": {
        "id": "ab8c94e7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "lab=le.fit_transform(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2869770e",
      "metadata": {
        "id": "2869770e"
      },
      "outputs": [],
      "source": [
        "type(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1af2bd04",
      "metadata": {
        "id": "1af2bd04"
      },
      "outputs": [],
      "source": [
        "type(lab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3536af9f",
      "metadata": {
        "id": "3536af9f"
      },
      "source": [
        "Train and test dataset spilt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0e55f94c",
      "metadata": {
        "id": "0e55f94c"
      },
      "outputs": [],
      "source": [
        "train_images,test_images,train_labels,test_labels=train_test_split(data,lab,test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a41742ca",
      "metadata": {
        "id": "a41742ca"
      },
      "outputs": [],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "001342f9",
      "metadata": {
        "id": "001342f9"
      },
      "outputs": [],
      "source": [
        "print('Train Dataset Size:',np.size(train_labels))\n",
        "print('Test Dataset Size:',np.size(test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9796106",
      "metadata": {
        "id": "b9796106"
      },
      "outputs": [],
      "source": [
        "np.unique(test_labels,return_counts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33a6d409",
      "metadata": {
        "id": "33a6d409"
      },
      "source": [
        "# Define the CNN architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73ab126f",
      "metadata": {
        "id": "73ab126f"
      },
      "source": [
        "Create the convolutional base\n",
        "\n",
        "1. Convolutional : 32 filters 3x3\n",
        "2. Maxpooling: 2x2\n",
        "3. Convolutional : 64 filters 5x5\n",
        "4. Convolutional : 32 filters 3x3\n",
        "5. Maxpooling: 3x3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "01322894",
      "metadata": {
        "id": "01322894"
      },
      "outputs": [],
      "source": [
        "network=models.Sequential()\n",
        "network.add(layers.Conv2D(32,(3,3),activation='relu', input_shape=(100,100,3)))\n",
        "network.add(layers.MaxPooling2D((2,2)))\n",
        "network.add(layers.Conv2D(64,(7,7),activation='relu'))\n",
        "network.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
        "network.add(layers.MaxPooling2D((3,3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fa63e7a",
      "metadata": {
        "id": "0fa63e7a"
      },
      "source": [
        "Check summary of convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e8ac882",
      "metadata": {
        "id": "0e8ac882"
      },
      "outputs": [],
      "source": [
        "network.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e49eab1",
      "metadata": {
        "id": "7e49eab1"
      },
      "source": [
        "Build the classifier on top of the convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "99a58d24",
      "metadata": {
        "id": "99a58d24"
      },
      "outputs": [],
      "source": [
        "network.add(layers.Flatten())\n",
        "network.add(layers.Dense(80,activation='relu'))\n",
        "network.add(layers.Dense(50,activation='relu'))\n",
        "network.add(layers.Dense(2,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f7ba93f",
      "metadata": {
        "id": "7f7ba93f"
      },
      "outputs": [],
      "source": [
        "network.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf809688",
      "metadata": {
        "id": "bf809688"
      },
      "source": [
        "Compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "226df6b8",
      "metadata": {
        "id": "226df6b8"
      },
      "outputs": [],
      "source": [
        "network.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a02dcf5a",
      "metadata": {
        "id": "a02dcf5a"
      },
      "outputs": [],
      "source": [
        "trained_network=network.fit(train_images,train_labels,epochs=30,validation_data=(test_images,test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5039efe",
      "metadata": {
        "id": "e5039efe"
      },
      "outputs": [],
      "source": [
        "plt.plot(trained_network.history['accuracy'],label='Training Accuracy')\n",
        "plt.plot(trained_network.history['val_accuracy'],label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0,1.1])\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44db3a23",
      "metadata": {
        "id": "44db3a23"
      },
      "outputs": [],
      "source": [
        "plt.plot(trained_network.history['loss'],label='Training Loss')\n",
        "plt.plot(trained_network.history['val_loss'],label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "656e1c17",
      "metadata": {
        "id": "656e1c17"
      },
      "source": [
        "Evaluate the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2476b8e5",
      "metadata": {
        "id": "2476b8e5"
      },
      "outputs": [],
      "source": [
        "test_loss,test_acc=network.evaluate(test_images,test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa6cec7b",
      "metadata": {
        "id": "aa6cec7b"
      },
      "outputs": [],
      "source": [
        "y_predict=network.predict(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb5ef5da",
      "metadata": {
        "id": "cb5ef5da"
      },
      "outputs": [],
      "source": [
        "y_pred=[]\n",
        "for val in y_predict:\n",
        "    y_pred.append(np.argmax(val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b9d88d",
      "metadata": {
        "id": "51b9d88d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac88f112-8df0-4b80-c9ca-1e2eb48434c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17  0]\n",
            " [23  0]]\n"
          ]
        }
      ],
      "source": [
        "print(metrics.confusion_matrix(test_labels,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cce68d11",
      "metadata": {
        "scrolled": true,
        "id": "cce68d11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac9b94f-548e-4ff8-9684-f4fc4d9ecdc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.425\n"
          ]
        }
      ],
      "source": [
        "print(metrics.accuracy_score(test_labels,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "953752c2",
      "metadata": {
        "id": "953752c2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in network.layers:\n",
        "    if 'conv' in layer.name:\n",
        "        weights, bias= layer.get_weights()\n",
        "        #print(layer.name, filters.shape)\n",
        "\n",
        "        #normalize filter values between  0 and 1 for visualization\n",
        "        f_min, f_max = weights.min(), weights.max()\n",
        "        filters = (weights - f_min) / (f_max - f_min)\n",
        "        print(filters.shape[3])\n",
        "        filter_cnt=1\n",
        "\n",
        "        #plotting all the filters\n",
        "        for i in range(filters.shape[3]):\n",
        "            #get the filters\n",
        "            filt=filters[:,:,:, i]\n",
        "            #plotting each of the channel, color image RGB channels\n",
        "            for j in range(filters.shape[0]):\n",
        "                ax= plt.subplot(filters.shape[3], filters.shape[0], filter_cnt  )\n",
        "                ax.set_xticks([])\n",
        "                ax.set_yticks([])\n",
        "                plt.imshow(filt[:,:, 1])\n",
        "                filter_cnt+=1\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "JSyZQD-NgvU2"
      },
      "id": "JSyZQD-NgvU2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img"
      ],
      "metadata": {
        "id": "FHsl4WBH08no"
      },
      "id": "FHsl4WBH08no",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path='' #dementia\n",
        "# Define a new Model, Input= image\n",
        "# Output= intermediate representations for all layers in the\n",
        "# previous model after the first.\n",
        "successive_outputs = [layer.output for layer in network.layers[1:]]\n",
        "#visualization_model = Model(img_input, successive_outputs)\n",
        "visualization_model = tf.keras.models.Model(inputs = network.input,\n",
        "                                            outputs = successive_outputs)\n",
        "#Load the input image\n",
        "img = load_img(img_path, target_size=(100, 100))\n",
        "# Convert ht image to Array of dimension (100,100,3)\n",
        "x   = img_to_array(img)\n",
        "x   = x.reshape((1,) + x.shape)\n",
        "# Rescale by 1/255\n",
        "x /= 255.0\n",
        "# Let's run input image through our vislauization network\n",
        "# to obtain all intermediate representations for the image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "# Retrieve are the names of the layers, so can have them as part of our plot\n",
        "layer_names = [layer.name for layer in network.layers]\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  print(feature_map.shape)\n",
        "  if len(feature_map.shape) == 4:\n",
        "\n",
        "    # Plot Feature maps for the conv / maxpool layers, not the fully-connected layers\n",
        "\n",
        "    n_features = feature_map.shape[-1]  # number of features in the feature map\n",
        "    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n",
        "\n",
        "    # We will tile our images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "\n",
        "    # Postprocess the feature to be visually palatable\n",
        "    for i in range(n_features):\n",
        "      x  = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std ()\n",
        "      x *=  64\n",
        "      x += 128\n",
        "      x  = np.clip(x, 0, 255).astype('uint8')\n",
        "      # Tile each filter into a horizontal grid\n",
        "      display_grid[:, i * size : (i + 1) * size] = x\n",
        "# Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure( figsize=(scale * n_features, scale) )\n",
        "    plt.title ( layer_name )\n",
        "    plt.grid  ( False )\n",
        "    plt.imshow( display_grid, aspect='auto', cmap='viridis' )"
      ],
      "metadata": {
        "id": "5jCLGMt9zTdm"
      },
      "id": "5jCLGMt9zTdm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}